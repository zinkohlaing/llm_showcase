{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airline AI Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple chatbot that will use the existing functions defined in this notebook to look up flight information and return the prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyCU\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I will add two tools that include two functions.\n",
    "\n",
    "First function is to simply return the flight ticket prices based on destination.\n",
    "\n",
    "Second function, more advanced function, returns the flight ticket information based on the destination and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"singapore\": \"$3500\", \"new york\": \"$4000\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price called for singapore\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$3500'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price(\"singapore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time slots\n",
    "TIME_SLOTS = {\n",
    "    \"morning\": \"06:00-12:00\",\n",
    "    \"afternoon\": \"12:00-18:00\",\n",
    "    \"evening\": \"18:00-24:00\",\n",
    "    \"night\": \"00:00-06:00\"\n",
    "}\n",
    "\n",
    "# Define base prices and time-based multipliers\n",
    "ticket_prices = {\n",
    "    \"london\": {\n",
    "        \"base_price\": 799,\n",
    "        \"time_multipliers\": {\n",
    "            \"morning\": 1.2,    # 20% more expensive\n",
    "            \"afternoon\": 1.0,  # standard price\n",
    "            \"evening\": 0.8,    # 20% cheaper\n",
    "            \"night\": 0.6      # 40% cheaper\n",
    "        }\n",
    "    },\n",
    "    \"paris\": {\n",
    "        \"base_price\": 899,\n",
    "        \"time_multipliers\": {\n",
    "            \"morning\": 1.1,\n",
    "            \"afternoon\": 1.0,\n",
    "            \"evening\": 0.9,\n",
    "            \"night\": 0.7\n",
    "        }\n",
    "    },\n",
    "    \"singapore\": {\n",
    "        \"base_price\": 3500,\n",
    "        \"time_multipliers\": {\n",
    "            \"morning\": 1.1,\n",
    "            \"afternoon\": 1.0,\n",
    "            \"evening\": 0.9,\n",
    "            \"night\": 0.7\n",
    "        }\n",
    "    },\n",
    "    \"new york\": {\n",
    "        \"base_price\": 4000,\n",
    "        \"time_multipliers\": {\n",
    "            \"morning\": 1.1,\n",
    "            \"afternoon\": 1.0,\n",
    "            \"evening\": 0.9,\n",
    "            \"night\": 0.7\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function with time and destinations\n",
    "\n",
    "def get_ticket_price_with_time(destination_city, time_slot):\n",
    "    \"\"\"\n",
    "    Get the price of a ticket based on destination and time slot.\n",
    "    \n",
    "    Args:\n",
    "        destination_city (str): The destination city\n",
    "        time_slot (str): One of 'morning', 'afternoon', 'evening', 'night'\n",
    "    \n",
    "    Returns:\n",
    "        float: The calculated price\n",
    "    \"\"\"\n",
    "    print(f\"Tool get_ticket_price_with_time called for {destination_city} at {time_slot}\")\n",
    "    city = destination_city.lower()\n",
    "    time_slot = time_slot.lower()\n",
    "    \n",
    "    if city not in ticket_prices:\n",
    "        return \"Unknown destination\"\n",
    "    \n",
    "    if time_slot not in TIME_SLOTS:\n",
    "        return \"Invalid time slot\"\n",
    "    \n",
    "    base_price = ticket_prices[city][\"base_price\"]\n",
    "    multiplier = ticket_prices[city][\"time_multipliers\"][time_slot]\n",
    "    \n",
    "    final_price = base_price * multiplier\n",
    "    return f\"${final_price:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price_with_time called for singapore at night\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$2450.00'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price_with_time(\"singapore\", \"night\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description is important for LLM to understand the price function\n",
    "\n",
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated function for LLM\n",
    "time_price_function = {\n",
    "    \"name\": \"get_ticket_price_with_time\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city based on the time of flight. Call this whenever you need to know the ticket price for a specific time, for example when a customer asks 'How much is a morning flight to this city' or 'What are the prices for different times of day'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "            \"time_slot\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The time slot for the flight (morning, afternoon, evening, or night)\",\n",
    "                \"enum\": [\"morning\", \"afternoon\", \"evening\", \"night\"]\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"destination_city\", \"time_slot\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": price_function}, {\"type\": \"function\", \"function\": time_price_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated handle tool call\n",
    "def handle_tool_call(message):\n",
    "    responses = []\n",
    "    \n",
    "    # Loop through all tool calls\n",
    "    for tool_call in message.tool_calls:\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        if tool_call.function.name == \"get_ticket_price_with_time\":\n",
    "            city = arguments.get('destination_city')\n",
    "            time_slot = arguments.get('time_slot')\n",
    "            price = get_ticket_price_with_time(city, time_slot)\n",
    "            response = {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": json.dumps({\n",
    "                    \"destination_city\": city,\n",
    "                    \"time_slot\": time_slot,\n",
    "                    \"price\": price\n",
    "                }),\n",
    "                \"tool_call_id\": tool_call.id\n",
    "            }\n",
    "            responses.append(response)\n",
    "        \n",
    "        elif tool_call.function.name == \"get_ticket_price\":\n",
    "            city = arguments.get('destination_city')\n",
    "            price = get_ticket_price(city)\n",
    "            response = {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": json.dumps({\n",
    "                    \"destination_city\": city,\n",
    "                    \"price\": price\n",
    "                }),\n",
    "                \"tool_call_id\": tool_call.id\n",
    "            }\n",
    "            responses.append(response)\n",
    "    \n",
    "    # Return all responses\n",
    "    return responses, None  # The second return value is not used in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated chat function\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "    if response.choices[0].finish_reason == \"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        responses, _ = handle_tool_call(message)\n",
    "        \n",
    "        # Add the assistant's message with tool calls\n",
    "        messages.append(message)\n",
    "        \n",
    "        # Add all tool responses\n",
    "        for response in responses:\n",
    "            messages.append(response)\n",
    "            \n",
    "        # Make a second API call to get the final response\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price called for Singapore\n",
      "Tool get_ticket_price_with_time called for Singapore at morning\n",
      "Tool get_ticket_price_with_time called for Singapore at afternoon\n",
      "Tool get_ticket_price_with_time called for Singapore at evening\n",
      "Tool get_ticket_price_with_time called for Singapore at night\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running this on local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Using cached ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in /opt/anaconda3/lib/python3.12/site-packages (from ollama) (0.27.0)\n",
      "Collecting pydantic<3.0.0,>=2.9.0 (from ollama)\n",
      "  Downloading pydantic-2.11.2-py3-none-any.whl.metadata (64 kB)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (1.0.2)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.6.0)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Downloading pydantic_core-2.33.1-cp312-cp312-macosx_10_12_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Downloading typing_extensions-4.13.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Using cached ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Downloading pydantic-2.11.2-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp312-cp312-macosx_10_12_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.13.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-extensions, typing-inspection, pydantic-core, pydantic, ollama\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.20.1\n",
      "    Uninstalling pydantic_core-2.20.1:\n",
      "      Successfully uninstalled pydantic_core-2.20.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.8.2\n",
      "    Uninstalling pydantic-2.8.2:\n",
      "      Successfully uninstalled pydantic-2.8.2\n",
      "Successfully installed ollama-0.4.7 pydantic-2.11.2 pydantic-core-2.33.1 typing-extensions-4.13.1 typing-inspection-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ollama pull gemma3:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the message for Ollama\n",
    "\n",
    "def format_messages_for_ollama(messages):\n",
    "    \"\"\"Convert OpenAI message format to Ollama format\"\"\"\n",
    "    formatted_messages = []\n",
    "    \n",
    "    for msg in messages:\n",
    "        if msg[\"role\"] == \"system\":\n",
    "            # Ollama treats system message as a special case\n",
    "            continue\n",
    "        elif msg[\"role\"] == \"tool\":\n",
    "            # Convert tool responses to assistant messages for Ollama\n",
    "            formatted_messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": f\"Tool response: {msg['content']}\"\n",
    "            })\n",
    "        else:\n",
    "            # User and assistant messages can be passed as is\n",
    "            formatted_messages.append(msg)\n",
    "    \n",
    "    return formatted_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history, use_ollama=False):\n",
    "    # Convert history from Gradio format to OpenAI format\n",
    "    formatted_history = []\n",
    "    for user_msg, assistant_msg in history:\n",
    "        formatted_history.append({\"role\": \"user\", \"content\": user_msg})\n",
    "        if assistant_msg:  # Only add assistant message if it exists\n",
    "            formatted_history.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + formatted_history + [{\"role\": \"user\", \"content\": message}]\n",
    "    \n",
    "    if use_ollama:\n",
    "        # Ollama implementation...\n",
    "        # (rest of the Ollama code remains the same)\n",
    "        pass\n",
    "    else:\n",
    "        # OpenAI implementation\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "        if response.choices[0].finish_reason == \"tool_calls\":\n",
    "            message = response.choices[0].message\n",
    "            responses, _ = handle_tool_call(message)\n",
    "            \n",
    "            messages.append(message)\n",
    "            for response in responses:\n",
    "                messages.append(response)\n",
    "                \n",
    "            response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "        \n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/gradio/chat_interface.py:334: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price_with_time called for Singapore at morning\n",
      "Tool get_ticket_price_with_time called for Singapore at afternoon\n",
      "Tool get_ticket_price_with_time called for Singapore at evening\n",
      "Tool get_ticket_price_with_time called for Singapore at night\n",
      "Tool get_ticket_price called for Singapore\n"
     ]
    }
   ],
   "source": [
    "# updated gradio interface to switch between OpenAI and Ollama\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# FlightAI Assistant\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        use_ollama = gr.Checkbox(label=\"Use Ollama (Local LLM)\", value=False)\n",
    "    \n",
    "    chatbot = gr.ChatInterface(\n",
    "        fn=lambda message, history: chat(message, history, use_ollama.value)\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
